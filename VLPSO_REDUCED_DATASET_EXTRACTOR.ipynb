{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLPSO_REDUCED DATASET EXTRACTOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEVvOlRZGnBc"
      },
      "source": [
        "Used to get the reduced dataset from the selected feature index in the text file for vlpso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M2RjidYuAMx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder()\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "path_to_txt_files='/content/drive/My Drive/FYP/VLPSO_TXTFILES'\n",
        "txt_files=os.listdir(path_to_txt_files)\n",
        "for fn in txt_files:\n",
        "  with open(('%s%s')%(path_to_txt_files,fn), 'r') as file:\n",
        "      tarr=fn.split('-')\n",
        "      ds_name=re.sub('.arff$', '', tarr[0])\n",
        "      sub_folder=re.sub('.txt$','',tarr[1])\n",
        "      if not os.path.exists(('%s%s')%('/content/drive/My Drive/FYP/VLPSO/',ds_name)):\n",
        "        os.makedirs(('%s%s')%('/content/drive/My Drive/FYP/VLPSO/',ds_name))\n",
        "      if  not os.path.exists(('%s%s/%s')%('/content/drive/My Drive/FYP/VLPSO/',ds_name,sub_folder)):\n",
        "        os.makedirs(('%s%s/%s')%('/content/drive/My Drive/FYP/VLPSO/',ds_name,sub_folder))\n",
        "      fold = file.read()\n",
        "      iteration_fold=fold.split(';')\n",
        "      ic=1\n",
        "      for iteration in iteration_fold:\n",
        "        sele_fid=iteration.split(',')\n",
        "        df=pd.read_csv(('/content/drive/My Drive/FYP/Dataset/%s.csv')%(ds_name))\n",
        "        df=df.replace('?',np.nan)\n",
        "        enc.fit(df[df.columns[-1]])\n",
        "        df[df.columns[-1]] = enc.transform(df[df.columns[-1]])\n",
        "        imp=imp.fit(df)\n",
        "        data_arr=imp.transform(df)\n",
        "        df= pd.DataFrame(data=data_arr,columns=df.columns)\n",
        "        #iteration=re.sub(r\"[\\n\\t\\s]*\", \"\", iteration)\n",
        "        iteration=iteration.split(',')\n",
        "        iteration.append(len(df.columns)-1)\n",
        "        iteration=np.array(iteration)\n",
        "        try:\n",
        "          iteration=iteration.astype(float)\n",
        "          iteration=iteration.astype(int)\n",
        "          X=df.values\n",
        "          reduced_dataset=X[:,iteration]\n",
        "          DF = pd.DataFrame(reduced_dataset)\n",
        "          DF.columns=df.columns[iteration]\n",
        "          print(DF.head())\n",
        "          DF..to_csv(('%s%s/%s/iteration%d.csv')%('/content/drive/My Drive/FYP/VLPSO/',ds_name,sub_folder,ic))\n",
        "          ic+=1\n",
        "          print(\"********\")\n",
        "        except:\n",
        "          print(iteration)\n",
        "          pass\n",
        "        #print(df.iloc[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}